{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Regression Model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-By-Step Assignment Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Assignment Topic:\n",
    "\n",
    "In this project, you will build a regression model using the Keras library to model the same data about concrete compressive strength that we used in labs 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Concrete Data:\n",
    "\n",
    "For your convenience, the data can be found here again: https://cocl.us/concrete_data. To recap, the predictors in the data of concrete strength include: Cement, Blast Furnace Slag, Fly Ash, Water, Superplasticizer, Coarse Aggregate, Fine Aggregate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Assignment Instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Build a baseline model (5 marks)\n",
    "\n",
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "- One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "- Use the adam optimizer and the mean squared error as the loss function.\n",
    "\n",
    "1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_splithelper function from Scikit-learn.\n",
    "\n",
    "2. Train the model on the training data using 50 epochs.\n",
    "\n",
    "3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "5. Report the mean and the standard deviation of the mean squared errors.\n",
    "\n",
    "Submit your Jupyter Notebook with your code and comments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the pandas, the numpy, the keras libraries and the packages from the keras library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "#import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  \n",
       "5             932.0           670.0   90     47.03  \n",
       "6             932.0           594.0  365     43.70  \n",
       "7             932.0           594.0   28     36.45  \n",
       "8             932.0           670.0   28     45.85  \n",
       "9             932.0           594.0   28     39.29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
    "concrete_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many point in the data frame, missing values, and genetal information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into target (strength) and (predictors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "5    47.03\n",
       "6    43.70\n",
       "7    36.45\n",
       "8    45.85\n",
       "9    39.29\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = concrete_data['Strength']\n",
    "target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "5   266.0               114.0      0.0  228.0               0.0   \n",
       "6   380.0                95.0      0.0  228.0               0.0   \n",
       "7   380.0                95.0      0.0  228.0               0.0   \n",
       "8   266.0               114.0      0.0  228.0               0.0   \n",
       "9   475.0                 0.0      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  \n",
       "5             932.0           670.0   90  \n",
       "6             932.0           594.0  365  \n",
       "7             932.0           594.0   28  \n",
       "8             932.0           670.0   28  \n",
       "9             932.0           594.0   28  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = concrete_data.iloc[:, :-1]\n",
    "predictors.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that defines our regression model for us so that we can conveniently call it to create our model:\n",
    " - One hidden layer of 10 nodes, and a ReLU activation function\n",
    " - Use the adam optimizer and the mean squared error as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#num of inputs = num of predictors colums\n",
    "n_cols = predictors.shape[1]\n",
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data for validation and we will train the model for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle #1: mean_squared_error 311.99102363462976\n",
      "Cycle #2: mean_squared_error 121.93921500888071\n",
      "Cycle #3: mean_squared_error 77.06328409929492\n",
      "Cycle #4: mean_squared_error 82.26685639415358\n",
      "Cycle #5: mean_squared_error 66.72646599680088\n",
      "Cycle #6: mean_squared_error 71.76137834073656\n",
      "Cycle #7: mean_squared_error 63.70086477335217\n",
      "Cycle #8: mean_squared_error 51.03346031460561\n",
      "Cycle #9: mean_squared_error 67.62978517353342\n",
      "Cycle #10: mean_squared_error 62.68017279368774\n",
      "Cycle #11: mean_squared_error 56.541851574549014\n",
      "Cycle #12: mean_squared_error 61.658052882716106\n",
      "Cycle #13: mean_squared_error 48.749507632456165\n",
      "Cycle #14: mean_squared_error 54.34474295705653\n",
      "Cycle #15: mean_squared_error 50.12402348688119\n",
      "Cycle #16: mean_squared_error 42.35458760431283\n",
      "Cycle #17: mean_squared_error 52.10623561525808\n",
      "Cycle #18: mean_squared_error 50.08295312282723\n",
      "Cycle #19: mean_squared_error 46.84086712587227\n",
      "Cycle #20: mean_squared_error 52.57823255224135\n",
      "Cycle #21: mean_squared_error 44.38899003186272\n",
      "Cycle #22: mean_squared_error 48.853025652444096\n",
      "Cycle #23: mean_squared_error 44.75679713622652\n",
      "Cycle #24: mean_squared_error 46.47180212817146\n",
      "Cycle #25: mean_squared_error 49.123125267646074\n",
      "Cycle #26: mean_squared_error 46.02437777966743\n",
      "Cycle #27: mean_squared_error 45.49386064597318\n",
      "Cycle #28: mean_squared_error 44.19865456985424\n",
      "Cycle #29: mean_squared_error 44.374509385488565\n",
      "Cycle #30: mean_squared_error 45.969408992038964\n",
      "Cycle #31: mean_squared_error 49.72642044264908\n",
      "Cycle #32: mean_squared_error 43.23431221181135\n",
      "Cycle #33: mean_squared_error 46.9361809418811\n",
      "Cycle #34: mean_squared_error 39.62278553737406\n",
      "Cycle #35: mean_squared_error 42.626645480159034\n",
      "Cycle #36: mean_squared_error 43.17451852347858\n",
      "Cycle #37: mean_squared_error 47.008691250699236\n",
      "Cycle #38: mean_squared_error 50.56580844126087\n",
      "Cycle #39: mean_squared_error 43.333876230184316\n",
      "Cycle #40: mean_squared_error 48.67419978021418\n",
      "Cycle #41: mean_squared_error 43.63893823716247\n",
      "Cycle #42: mean_squared_error 40.5743680910771\n",
      "Cycle #43: mean_squared_error 42.945307339665185\n",
      "Cycle #44: mean_squared_error 42.62743630764168\n",
      "Cycle #45: mean_squared_error 42.03357666904486\n",
      "Cycle #46: mean_squared_error 36.787703825817914\n",
      "Cycle #47: mean_squared_error 50.62104130717157\n",
      "Cycle #48: mean_squared_error 45.54429359806394\n",
      "Cycle #49: mean_squared_error 42.21291943892692\n",
      "Cycle #50: mean_squared_error 41.51902205581418\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 56.70472316766634\n",
      "The standard deviation of the mean squared errors: 39.03014606243445\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Normalize the data (5 marks)\n",
    "\n",
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the data by substracting the mean and dividing by the standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-1.291914</td>\n",
       "      <td>0.701883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.945704</td>\n",
       "      <td>0.244603</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.945704</td>\n",
       "      <td>0.244603</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.145138</td>\n",
       "      <td>0.464818</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-1.291914</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.854740</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "5 -0.145138            0.464818 -0.846733  2.174405         -1.038638   \n",
       "6  0.945704            0.244603 -0.846733  2.174405         -1.038638   \n",
       "7  0.945704            0.244603 -0.846733  2.174405         -1.038638   \n",
       "8 -0.145138            0.464818 -0.846733  2.174405         -1.038638   \n",
       "9  1.854740           -0.856472 -0.846733  2.174405         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  \n",
       "5         -0.526262       -1.291914  0.701883  \n",
       "6         -0.526262       -2.239829  5.055221  \n",
       "7         -0.526262       -2.239829 -0.279597  \n",
       "8         -0.526262       -1.291914 -0.279597  \n",
       "9         -0.526262       -2.239829 -0.279597  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm = (predictors - predictors.mean())/predictors.std()\n",
    "predictors_norm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cols = predictors_norm.shape[1]\n",
    "def regression_model2():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model2.add(Dense(1))\n",
    "    \n",
    "    model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model2\n",
    "\n",
    "model2 = regression_model2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data for validation and we will train the model for 50 epochs. **And use predictors_norm instead of predictors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle #1: mean_squared_error 309.70854922791517\n",
      "Cycle #2: mean_squared_error 171.65027344342573\n",
      "Cycle #3: mean_squared_error 135.08761426314567\n",
      "Cycle #4: mean_squared_error 110.18458448490279\n",
      "Cycle #5: mean_squared_error 104.77703420398305\n",
      "Cycle #6: mean_squared_error 82.0043884326725\n",
      "Cycle #7: mean_squared_error 69.09444679334325\n",
      "Cycle #8: mean_squared_error 71.53713822596282\n",
      "Cycle #9: mean_squared_error 67.52837274298312\n",
      "Cycle #10: mean_squared_error 76.34752514292893\n",
      "Cycle #11: mean_squared_error 61.52317869316027\n",
      "Cycle #12: mean_squared_error 55.39994879910861\n",
      "Cycle #13: mean_squared_error 60.70220243583605\n",
      "Cycle #14: mean_squared_error 56.56715467138198\n",
      "Cycle #15: mean_squared_error 48.343141339743404\n",
      "Cycle #16: mean_squared_error 53.0590337858231\n",
      "Cycle #17: mean_squared_error 50.38213857014974\n",
      "Cycle #18: mean_squared_error 51.014310077556125\n",
      "Cycle #19: mean_squared_error 40.60067456439861\n",
      "Cycle #20: mean_squared_error 49.64970301038625\n",
      "Cycle #21: mean_squared_error 47.769225086594865\n",
      "Cycle #22: mean_squared_error 47.25570549702567\n",
      "Cycle #23: mean_squared_error 43.87905127022259\n",
      "Cycle #24: mean_squared_error 43.55551363503663\n",
      "Cycle #25: mean_squared_error 46.38058058112185\n",
      "Cycle #26: mean_squared_error 49.22135104330612\n",
      "Cycle #27: mean_squared_error 45.205383177328265\n",
      "Cycle #28: mean_squared_error 47.41180824847669\n",
      "Cycle #29: mean_squared_error 44.896939743683944\n",
      "Cycle #30: mean_squared_error 45.718631423407004\n",
      "Cycle #31: mean_squared_error 44.00063194348974\n",
      "Cycle #32: mean_squared_error 48.60692568658625\n",
      "Cycle #33: mean_squared_error 44.234310557541335\n",
      "Cycle #34: mean_squared_error 43.3682580225676\n",
      "Cycle #35: mean_squared_error 39.63306562800238\n",
      "Cycle #36: mean_squared_error 47.70940370775735\n",
      "Cycle #37: mean_squared_error 47.53708801763343\n",
      "Cycle #38: mean_squared_error 52.585531117460874\n",
      "Cycle #39: mean_squared_error 38.89965401806877\n",
      "Cycle #40: mean_squared_error 42.814584404905254\n",
      "Cycle #41: mean_squared_error 42.11150160113585\n",
      "Cycle #42: mean_squared_error 52.080410367848415\n",
      "Cycle #43: mean_squared_error 48.812673599588834\n",
      "Cycle #44: mean_squared_error 48.580139221882746\n",
      "Cycle #45: mean_squared_error 43.230498650313194\n",
      "Cycle #46: mean_squared_error 40.20623838554308\n",
      "Cycle #47: mean_squared_error 38.50979693267723\n",
      "Cycle #48: mean_squared_error 40.066609786937924\n",
      "Cycle #49: mean_squared_error 47.131685695216106\n",
      "Cycle #50: mean_squared_error 44.51375241572803\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model2.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 61.6217672475179\n",
      "The standard deviation of the mean squared errors: 43.29149305783805\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean and the standard deviation of the mean squared errors in case A is less than in case B. But the difference is tiny. And in my opinion it's not a very good idea to compare result of two poor neural networks with one hidden layer only. Data normalization does not help a lot. Error is huge for both cases: A and B.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Increate the number of epochs (5 marks)\n",
    "\n",
    "Repeat Part B but use 100 epochs this time for training.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data (data after normalization) for validation and we will train the model **for 100 epochs instead of 50 epochs**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_model3():\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model3.add(Dense(1))\n",
    "    \n",
    "    model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model3\n",
    "\n",
    "model3 = regression_model3() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle #1: mean_squared_error 171.76414825538217\n",
      "Cycle #2: mean_squared_error 126.20202735481139\n",
      "Cycle #3: mean_squared_error 99.93021548373028\n",
      "Cycle #4: mean_squared_error 91.56857205980418\n",
      "Cycle #5: mean_squared_error 118.94827882834623\n",
      "Cycle #6: mean_squared_error 98.52066923962443\n",
      "Cycle #7: mean_squared_error 106.3992348581456\n",
      "Cycle #8: mean_squared_error 105.5089927352362\n",
      "Cycle #9: mean_squared_error 90.22434390169903\n",
      "Cycle #10: mean_squared_error 99.9333952375986\n",
      "Cycle #11: mean_squared_error 103.66797721887484\n",
      "Cycle #12: mean_squared_error 103.32750378457473\n",
      "Cycle #13: mean_squared_error 102.73060336313587\n",
      "Cycle #14: mean_squared_error 101.56693193750473\n",
      "Cycle #15: mean_squared_error 100.97896104337327\n",
      "Cycle #16: mean_squared_error 95.15525205544283\n",
      "Cycle #17: mean_squared_error 90.31244521156484\n",
      "Cycle #18: mean_squared_error 105.96080550406744\n",
      "Cycle #19: mean_squared_error 102.99081880143545\n",
      "Cycle #20: mean_squared_error 94.17879705830299\n",
      "Cycle #21: mean_squared_error 103.44617190561634\n",
      "Cycle #22: mean_squared_error 98.83152025340058\n",
      "Cycle #23: mean_squared_error 118.21411905628192\n",
      "Cycle #24: mean_squared_error 105.12463438163684\n",
      "Cycle #25: mean_squared_error 98.27649224537475\n",
      "Cycle #26: mean_squared_error 106.23147318818422\n",
      "Cycle #27: mean_squared_error 108.05662948954067\n",
      "Cycle #28: mean_squared_error 104.00444796170231\n",
      "Cycle #29: mean_squared_error 106.22262523860994\n",
      "Cycle #30: mean_squared_error 101.27448314679093\n",
      "Cycle #31: mean_squared_error 92.75841280248945\n",
      "Cycle #32: mean_squared_error 94.20431197576924\n",
      "Cycle #33: mean_squared_error 96.45779152286863\n",
      "Cycle #34: mean_squared_error 97.12835221768968\n",
      "Cycle #35: mean_squared_error 106.99071771813057\n",
      "Cycle #36: mean_squared_error 101.58685423718302\n",
      "Cycle #37: mean_squared_error 110.01574319388874\n",
      "Cycle #38: mean_squared_error 110.90825586411559\n",
      "Cycle #39: mean_squared_error 105.83000113971796\n",
      "Cycle #40: mean_squared_error 76.4903643956848\n",
      "Cycle #41: mean_squared_error 97.09450224842455\n",
      "Cycle #42: mean_squared_error 86.36875367396087\n",
      "Cycle #43: mean_squared_error 107.29562126085597\n",
      "Cycle #44: mean_squared_error 104.56463630454054\n",
      "Cycle #45: mean_squared_error 101.43293821464465\n",
      "Cycle #46: mean_squared_error 92.02120813659866\n",
      "Cycle #47: mean_squared_error 83.48770882319478\n",
      "Cycle #48: mean_squared_error 91.34322139900479\n",
      "Cycle #49: mean_squared_error 97.6155198970659\n",
      "Cycle #50: mean_squared_error 98.4634412500079\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model3.fit(X_train, y_train, epochs=100, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 102.2322185415126\n",
      "The standard deviation of the mean squared errors: 13.119447707016194\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean and the standard deviation of the mean squared errors in case C is bigger than in case B. But in both cases error is huge. In my opinion it's not a very good idea to compare result of two poor neural networks with one hidden layer only. Number of epoch does not help.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Increase the number of hidden layers (5 marks)\n",
    "\n",
    "Repeat part B but use a neural network with the following instead:\n",
    "\n",
    "- Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model with **three hidden layers, each of 10 nodes and ReLU activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_model4():\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model4.add(Dense(10, activation='relu'))\n",
    "    model4.add(Dense(10, activation='relu'))\n",
    "    model4.add(Dense(1))\n",
    "    \n",
    "    model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a new model with 3 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = regression_model4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model at the same time using the fit-method. We will leave out 30% of the data (data after normalization) for validation and we will train the model for 50 epochs and use **three hidden layers, each of 10 nodes and ReLU activation function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle #1: mean_squared_error 152.65070083766307\n",
      "Cycle #2: mean_squared_error 88.09756015419575\n",
      "Cycle #3: mean_squared_error 82.24099716630954\n",
      "Cycle #4: mean_squared_error 45.99169541639803\n",
      "Cycle #5: mean_squared_error 37.56291302430977\n",
      "Cycle #6: mean_squared_error 35.6977121482775\n",
      "Cycle #7: mean_squared_error 31.46599593054515\n",
      "Cycle #8: mean_squared_error 35.7753634036166\n",
      "Cycle #9: mean_squared_error 27.42970234522156\n",
      "Cycle #10: mean_squared_error 27.538042630192532\n",
      "Cycle #11: mean_squared_error 29.450146005377416\n",
      "Cycle #12: mean_squared_error 24.402957928605066\n",
      "Cycle #13: mean_squared_error 31.169564947727043\n",
      "Cycle #14: mean_squared_error 22.983247402030674\n",
      "Cycle #15: mean_squared_error 24.292332294303623\n",
      "Cycle #16: mean_squared_error 27.170813390737983\n",
      "Cycle #17: mean_squared_error 27.323440946807366\n",
      "Cycle #18: mean_squared_error 25.138819703778015\n",
      "Cycle #19: mean_squared_error 23.346316235736737\n",
      "Cycle #20: mean_squared_error 28.742703351388087\n",
      "Cycle #21: mean_squared_error 30.55783544003385\n",
      "Cycle #22: mean_squared_error 24.926635032332833\n",
      "Cycle #23: mean_squared_error 20.179393293016552\n",
      "Cycle #24: mean_squared_error 30.379257140421945\n",
      "Cycle #25: mean_squared_error 22.39127525465388\n",
      "Cycle #26: mean_squared_error 23.79716629966563\n",
      "Cycle #27: mean_squared_error 22.33534243808981\n",
      "Cycle #28: mean_squared_error 26.948316604959928\n",
      "Cycle #29: mean_squared_error 24.92424771083597\n",
      "Cycle #30: mean_squared_error 23.07874932644051\n",
      "Cycle #31: mean_squared_error 25.4220045577361\n",
      "Cycle #32: mean_squared_error 20.782299763948014\n",
      "Cycle #33: mean_squared_error 25.07743510150601\n",
      "Cycle #34: mean_squared_error 17.818534597995598\n",
      "Cycle #35: mean_squared_error 26.457570930900697\n",
      "Cycle #36: mean_squared_error 20.326257989630346\n",
      "Cycle #37: mean_squared_error 23.751390327527684\n",
      "Cycle #38: mean_squared_error 24.948538128997903\n",
      "Cycle #39: mean_squared_error 26.74443518999711\n",
      "Cycle #40: mean_squared_error 26.25410778699955\n",
      "Cycle #41: mean_squared_error 25.604493119570044\n",
      "Cycle #42: mean_squared_error 22.569007095781345\n",
      "Cycle #43: mean_squared_error 23.675922332072336\n",
      "Cycle #44: mean_squared_error 25.460453576640404\n",
      "Cycle #45: mean_squared_error 23.680965695180554\n",
      "Cycle #46: mean_squared_error 21.465474175018013\n",
      "Cycle #47: mean_squared_error 23.139124441301167\n",
      "Cycle #48: mean_squared_error 20.13439600058744\n",
      "Cycle #49: mean_squared_error 26.731519050968505\n",
      "Cycle #50: mean_squared_error 22.549516819827378\n"
     ]
    }
   ],
   "source": [
    "list_of_mean_squared_error = []\n",
    "for cycle in range(50):\n",
    "    #Randomly split the data into a training set (70%) and a test set (30%):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n",
    "    #Train and test the model at the same time\n",
    "    res = model4.fit(X_train, y_train, epochs=50, verbose=0, validation_data=(X_test, y_test))\n",
    "    #Find mean_squared_error as last value in history.\n",
    "    mean_squared_error = res.history['val_loss'][-1]\n",
    "    #Add value of mean_squared_error for every cycle in list.\n",
    "    list_of_mean_squared_error.append(mean_squared_error)\n",
    "    print('Cycle #{}: mean_squared_error {}'.format(cycle+1, mean_squared_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the mean and the standard deviation of the mean squared errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the mean squared errors: 31.011653809717178\n",
      "The standard deviation of the mean squared errors: 21.439497664953674\n"
     ]
    }
   ],
   "source": [
    "print('The mean of the mean squared errors: {}'.format(np.mean(list_of_mean_squared_error)))\n",
    "print('The standard deviation of the mean squared errors: {}'.format(np.std(list_of_mean_squared_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean and the standard deviation of the mean squared errors in case D is less than in case A, B and C. And it's the only case where error is not very big. It means additional layers in neural network are more important than other things. Also it proves the comparison between poor neural network with one hidden layer in previous cases is a bad idea. Result can be unpredictable.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
